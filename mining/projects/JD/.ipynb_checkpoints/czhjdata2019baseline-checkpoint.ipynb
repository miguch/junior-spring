{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'com_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d6f6d4ed36b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcom_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'com_util'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error\n",
    "from com_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "product_info=pd.read_csv(path+\"jdata_product.csv\")\n",
    "user_info=pd.read_csv(path+\"jdata_user.csv\")\n",
    "user_action=pd.read_csv(path+\"jdata_action.csv\")\n",
    "shop_info=pd.read_csv(path+\"jdata_shop.csv\")\n",
    "user_comment=pd.read_csv(path+\"jdata_comment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_action['a_date']=user_action['action_time'].apply(lambda x: str(x)[:10])\n",
    "# product_info['a_date']=product_info['']\n",
    "# user_info['a_date']=user_info['']\n",
    "\n",
    "# shop_info['a_date']=shop_info['']\n",
    "# user_comment['a_date']=user_comment['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_action.head())\n",
    "print(user_info.head())\n",
    "print(shop_info.head())\n",
    "print(product_info.head())\n",
    "print(user_comment.head())\n",
    "print(user_action.shape)\n",
    "print(user_info.shape)\n",
    "print(shop_info.shape)\n",
    "print(product_info.shape)\n",
    "print(user_comment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info.cate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类的思路baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "正样本的构建：已经购买的记录作为正样本\n",
    "初步想法：负样本的构建，当对一个商品一系列action后,过了两周都没有购买，将此记录记为负样本\n",
    "正常来说应该时间来分析\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#已经购买的商品id\n",
    "typebuy = user_action[user_action.type == 2][['user_id','sku_id']]\n",
    "typebuy.shape\n",
    "productbuy = typebuy.merge(user_action,on = ['user_id','sku_id'],how = 'left')\n",
    "productbuy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可能购买的商品id\n",
    "productpotential.shape\n",
    "user_action.sku_id.isin(typebuy.sku_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpbuy = productbuy.iloc[:,:].\\\n",
    "                groupby(['user_id','sku_id']).type.value_counts().unstack().reset_index() #.sort_values(by = 'action_time',ascending=True).\\\n",
    "tmpbuy.columns = ['user_id','sku_id']+['type'+str(i) for i in range(1,6)]\n",
    "tmpbuy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmppo = user_action.iloc[:,:].\\\n",
    "        groupby(['user_id','sku_id']).type.value_counts().unstack().add_prefix('type').reset_index()#sort_values(by = 'action_time',ascending=True).\\\n",
    "# tmppo.columns = ['user_id','sku_id']+['type'+str(i) for i in range(1,2)]\n",
    "tmppo.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#已经购买的记录作为正样本\n",
    "possamples = productbuy\n",
    "possamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "未购买的商品记录为潜在商品记录\n",
    "'''\n",
    "skupo = tmppo[tmppo.type2==0]\n",
    "skupo.head()\n",
    "skupo = skupo[['user_id','sku_id']]\n",
    "skupo.shape\n",
    "productpo = skupo.merge(user_action,on = ['user_id','sku_id'],how = 'left')\n",
    "productpo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "productpo = productpo.sort_values(by = ['user_id','sku_id'],kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "找出用户对某一商品的最新一次操作的时间\n",
    "#negsamples = 任一其它行为发生在2周前\n",
    "'''\n",
    "latestactiontime = []\n",
    "from tqdm import*\n",
    "\n",
    "for i in tqdm_notebook(range(60)):\n",
    "# for i in range(60):\n",
    "    print(i)\n",
    "    tmp = productpo[['user_id','sku_id','a_date']].iloc[i*500000:(i+1)*500000,:].groupby(['user_id','sku_id']).\\\n",
    "                    apply(lambda x: max(x.a_date)<'2018-04-01').rename('outdate').reset_index()\n",
    "    latestactiontime.append(tmp)\n",
    "tmp = productpo[['user_id','sku_id','a_date']].iloc[30000000:,:].groupby(['user_id','sku_id']).\\\n",
    "                    apply(lambda x: max(x.a_date)<'2018-04-01').rename('outdate').reset_index()\n",
    "latestactiontime = pd.concat(latestactiontime, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestactiontime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = latestactiontime[latestactiontime.outdate]\n",
    "negsamples = tmp.merge(productpo,on = ['user_id','sku_id'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "negsamples.drop(['outdate'],axis = 1,inplace=True)\n",
    "negsamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "潜在商品里取出了负样本，从剩下的记录里构建测试集数据\n",
    "初步思路：从最近一次操作的时间在一周内的记录作为测试集\n",
    "'''\n",
    "tmp = latestactiontime[~latestactiontime.outdate]\n",
    "testsamples = tmp.merge(productpo,on = ['user_id','sku_id'],how = 'left')\n",
    "testsamples.drop(['outdate'],axis = 1,inplace=True)\n",
    "testsamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetday = '2018-04-16'\n",
    "testsamples = testsamples.sort_values(by = ['user_id','sku_id'],kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastweek = testsamples[['user_id','sku_id','a_date']].groupby(['user_id','sku_id']).\\\n",
    "                    apply(lambda x: max(x.a_date)>'2018-04-08').rename('lastweek').reset_index()\n",
    "tmp = lastweek[lastweek.lastweek]\n",
    "testsamples = tmp.merge(testsamples,on = ['user_id','sku_id'],how = 'left')\n",
    "testsamples.drop(['lastweek'],axis = 1,inplace=True)\n",
    "testsamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_constuct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练集构建\n",
    "'''\n",
    "possamples['label'] = 1\n",
    "negsamples['label'] = 0\n",
    "trainraw = pd.concat([possamples,negsamples],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "将用户表和商品表连接，各自的信息可以作为初步的特征\n",
    "'''\n",
    "trainraw = trainraw.merge(user_info,on = 'user_id',how = 'left')\n",
    "trainraw = trainraw.merge(product_info,on = 'sku_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据量过大，在连接的时候要做内存优化\n",
    "初步：去掉object类型的列，将数值型的列用‘int’c存放在df中\n",
    "\n",
    "'''\n",
    "cols = [u'action_time', u'module_id','a_date',\n",
    "      u'user_reg_tm', u'market_time']\n",
    "trainraw = trainraw.drop(cols, axis= 1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainraw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainraw = trainraw.merge(shop_info,on = 'shop_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [u'shop_reg_tm', u'shop_id']\n",
    "trainraw = trainraw.drop(cols, axis= 1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据量过大，在连接的时候要做内存优化\n",
    "初步：去掉object类型的列，将数值型的列用‘int16’c存放在df中\n",
    "\n",
    "'''\n",
    "#内存优化\n",
    "cols = [u'type', u'label', u'age', u'sex', u'user_lv_cd',\n",
    "        u'city_level', u'province', u'city', u'county', u'brand', u'cate_x',\n",
    "        u'cate_y', u'shop_score']\n",
    "trainraw[cols] = trainraw[cols].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#对测试集做连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testraw = testsamples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testraw = testraw.merge(user_info,on = 'user_id',how = 'left')\n",
    "testraw = testraw.merge(product_info,on = 'sku_id',how = 'left')\n",
    "cols = [u'action_time', u'module_id','a_date',\n",
    "      u'user_reg_tm', u'market_time']\n",
    "testraw = testraw.drop(cols, axis= 1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testraw = testraw.merge(shop_info,on = 'shop_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [u'shop_reg_tm', u'shop_id']\n",
    "testraw = testraw.drop(cols, axis= 1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据量过大，在连接的时候要做内存优化\n",
    "初步：去掉object类型的列，将数值型的列用‘int16’c存放在df中\n",
    "\n",
    "'''\n",
    "#内存优化\n",
    "cols = [u'type', u'age', u'sex', u'user_lv_cd',\n",
    "        u'city_level', u'province', u'city', u'county', u'brand', u'cate_x',\n",
    "        u'cate_y', u'shop_score']\n",
    "testraw[cols] = testraw[cols].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fea_construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "用户对商品的历史行为记录，可以统计来做特征\n",
    "正常来说，应该结合时间顺序来考虑\n",
    "'''\n",
    "tmp = trainraw.groupby(['user_id','sku_id']).type.value_counts().unstack().add_prefix('type').fillna(0).astype('int16').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.fillna(0,inplace=True)\n",
    "traindata = trainraw.drop_duplicates(subset = ['user_id','sku_id'],keep='first')\n",
    "traindata = traindata.sort_values(by = ['user_id','sku_id'],kind='mergesort')\n",
    "tmp = tmp.sort_values(by = ['user_id','sku_id'],kind='mergesort')\n",
    "traindata = traindata.merge(tmp,on = ['user_id','sku_id'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = testraw.groupby(['user_id','sku_id']).type.value_counts().unstack().add_prefix('type').fillna(0).astype('int16').reset_index()\n",
    "# tmp.fillna(0,inplace=True)\n",
    "testdata = testraw.drop_duplicates(subset = ['user_id','sku_id'],keep='first')\n",
    "testdata = testdata.sort_values(by = ['user_id','sku_id'],kind='mergesort')\n",
    "tmp = tmp.sort_values(by = ['user_id','sku_id'],kind='mergesort')\n",
    "testdata = testdata.merge(tmp,on = ['user_id','sku_id'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindata.info())\n",
    "testdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.drop('type2',axis =1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = traindata[testdata.columns]\n",
    "X_test = testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = traindata['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 在做二分类的时候，样本不平衡，应当解决，降采样'''\n",
    "#降采样\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "# X_resampled, y_resampled = rus.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''初步尝试lgb作为分类器'''\n",
    "#lgb\n",
    "\n",
    "#数据集划分时在索引上容易出错，先对数据冲索引\n",
    "X_train = X_train.reset_index().drop('index',axis=1)\n",
    "Y_train = Y_train.reset_index().drop('index',axis=1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集划分时在索引上容易出错，先对数据冲索引\n",
    "X,x_no,Y,y_no = train_test_split(X_train,Y_train,train_size = 0.2,random_state = 2019)\n",
    "X = X.reset_index().drop('index',axis=1)\n",
    "Y = Y.reset_index().label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#官方评价指标\n",
    "def f11(y_true1,y_pred1):\n",
    "    r = recall_score(y_true=y_true1,y_pred=y_pred1)\n",
    "    p = precision_score(y_true=y_true1,y_pred=y_pred1)\n",
    "    return (3*r*p) / (2*r+p)\n",
    "\n",
    "def f12(y_true2,y_pred2):\n",
    "    r = recall_score(y_true=y_true2,y_pred=y_pred2)\n",
    "    p = precision_score(y_true=y_true2,y_pred=y_pred2)\n",
    "    return (5*r*p) / (2*r+3*p)\n",
    "def eval(f11,f12):\n",
    "    return 0.4*f11+0.6*f12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,KFold,train_test_split\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "seed = 2019\n",
    "n_splits=5\n",
    "kfold =  StratifiedShuffleSplit(n_splits=5, random_state = seed)\n",
    "prediction = 0\n",
    "'''\n",
    "实际上训练集和验证集应该按时间分开划分\n",
    "'''\n",
    "for idx,(trainindex,testindex) in enumerate(kfold.split(X,Y)):\n",
    "    x_train,x_test,y_train,y_test = X.iloc[trainindex],X.iloc[testindex],Y[trainindex],Y[testindex]\n",
    "    \n",
    "    x_tr = lgb.Dataset(x_train,label=y_train)\n",
    "    x_te = lgb.Dataset(x_test,label=y_test)\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',  # 设置提升类型\n",
    "        'objective': 'binary', # 目标函数\n",
    "        'metric': {'l2', 'auc'},  # 评估函数\n",
    "        'num_leaves': 31,   # 叶子节点数\n",
    "        'learning_rate': 0.05,  # 学习速率\n",
    "        'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "        'bagging_fraction': 0.9, # 建树的样本采样比例\n",
    "        'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "        'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "    }\n",
    "\n",
    "    bst = lgb.train(params, x_tr,10,valid_sets = [x_te] ,early_stopping_rounds=10,verbose_eval=20) \n",
    "    pred = bst.predict(x_test)\n",
    "    print(accuracy_score(y_test,pred>0.9))\n",
    "    \n",
    "    #5折平均作为最终的预测概率\n",
    "    prediction += bst.predict(X_test)\n",
    "prediction = prediction / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(prediction>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时序关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_test[prediction>0.5][['user_id','sku_id']]\n",
    "result = tmp.merge(product_info,on = 'sku_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['brand','sku_id','market_time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = result.drop_duplicates().dropna().astype(int)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[['user_id','cate','shop_id']]\n",
    "result.to_csv('../output/result'+ str(datetime.now().date())+'.csv',index = False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shop prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = user_action[user_action['a_date']<='2018-4-15'].merge(product_info,on = 'sku_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "date_wins = [\n",
    "#              ('2018-04-09','2018-04-15'),\n",
    "#              ('2018-04-02','2018-04-08'),\n",
    "#              ('2018-03-26','2018-04-01'),\n",
    "#              ('2018-03-19','2018-03-25'),\n",
    "#              ('2018-03-12','2018-03-18'),\n",
    "#              ('2018-03-05','2018-03-11'),\n",
    "#              ('2018-02-28','2018-03-04'),\n",
    "#              ('2018-02-21','2018-02-27'),\n",
    "#              ('2018-02-14','2018-02-20'),\n",
    "#              ('2018-02-07','2018-02-13'),\n",
    "#              ('2018-02-01','2018-02-06')\n",
    "            ]\n",
    "for date in date_wins:\n",
    "    start = datetime.datetime.now()\n",
    "    print('counting...'+date[0] + ' to '+ date[1])\n",
    "    tmp = samples[(samples['a_date']>=date[0])&(samples['a_date']<=date[1])].head(500000).groupby('user_id').shop_id.value_counts().unstack()\n",
    "    tmp.columns = ['shop'+str(int(i)) for i in tmp.columns]\n",
    "    tmp.fillna(0,inplace=True)\n",
    "    print('saving...'+date[0] + ' to ' + date[1])\n",
    "    print(tmp.shape)\n",
    "    tmp.to_csv('../data/user_shopmatrix'+date[0]+'.csv',index=False) \n",
    "    end = datetime.datetime.now()\n",
    "    print(end-start)\n",
    "# actionmatrix = samples.iloc[:3000000,:].groupby('user_id').shop_id.value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "date_wins = [\n",
    "             ('2018-04-09','2018-04-15'),\n",
    "             ('2018-04-02','2018-04-08'),\n",
    "             ('2018-03-26','2018-04-01'),\n",
    "             ('2018-03-19','2018-03-25'),\n",
    "             ('2018-03-12','2018-03-18'),\n",
    "             ('2018-03-05','2018-03-11'),\n",
    "             ('2018-02-28','2018-03-04'),\n",
    "             ('2018-02-21','2018-02-27'),\n",
    "             ('2018-02-14','2018-02-20'),\n",
    "             ('2018-02-07','2018-02-13'),\n",
    "             ('2018-02-01','2018-02-06')\n",
    "            ]\n",
    "for date in date_wins:\n",
    "    start = datetime.datetime.now()\n",
    "    print('counting...'+date[0] + ' to '+ date[1])\n",
    "    tmp = samples[(samples['a_date']>=date[0])&(samples['a_date']<=date[1])].head(500000).groupby('user_id').cate.value_counts().unstack()\n",
    "    tmp.columns = ['shop'+str(int(i)) for i in tmp.columns]\n",
    "    tmp.fillna(0,inplace=True)\n",
    "    print('saving...'+date[0] + ' to ' + date[1])\n",
    "    print(tmp.shape)\n",
    "    tmp.to_csv('../data/user_catematrix'+date[0]+'.csv',index=False) \n",
    "    end = datetime.datetime.now()\n",
    "    print(end-start)\n",
    "# actionmatrix = samples.iloc[:3000000,:].groupby('user_id').shop_id.value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionmatrix = pd.read_csv('../data/user_catematrix2018-04-09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 马尔可夫链/CRF解决时序问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catelabel=label.iloc[:,:].groupby(['user_id','a_date'])[\"cate\"].unique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "catelabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
