{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 21 09:48:09 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 415.27       Driver Version: 415.27       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:81:00.0 Off |                  N/A |\r\n",
      "|  0%   45C    P3    50W / 270W |      1MiB / 10989MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train-data'\n",
    "train_tfidf = np.load(os.path.join(train_dir, 'train_tfidf.npy'))[()]\n",
    "test_tfidf = np.load(os.path.join(train_dir, 'test_tfidf.npy'))[()]\n",
    "# Class will start with 0\n",
    "train_y = pd.read_csv(os.path.join(train_dir, 'train_y.csv')) - 1\n",
    "test_uid = pd.read_csv(os.path.join(train_dir, 'test_x.csv'))['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfDataset(Dataset):\n",
    "    def __init__(self, x: np.ndarray, y=None, **kwargs):\n",
    "\n",
    "      self.num_samples = x.shape[0]\n",
    "\n",
    "      if y is not None:\n",
    "          # Train\n",
    "          self.y = y.values.reshape(-1, 1)\n",
    "      else:\n",
    "          # Test\n",
    "          self.y = np.zeros((self.num_samples, 1))\n",
    "        \n",
    "      self.x = x\n",
    "    \n",
    "      self.init_kwargs = kwargs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.x[idx].astype('float32').toarray(), self.y[idx].squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    def __init__(self, input_length, num_classes, conv_layers, lin_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Conv\n",
    "        # conv over the whole vector\n",
    "        conv1 = nn.Conv1d(1, 50, input_length)\n",
    "        avg_pool1 = nn.AdaptiveAvgPool1d(1)\n",
    "        max_pool1 = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.conv_list = nn.ModuleList([conv1] + [nn.Conv1d(1, out_channel, kernel, stride=1) \n",
    "                                              for out_channel, kernel in conv_layers])\n",
    "        self.avg_pool_list = nn.ModuleList([avg_pool1] + [nn.AdaptiveAvgPool1d(1) \n",
    "                                              for out_channel, kernel in conv_layers])\n",
    "        self.max_pool_list = nn.ModuleList([max_pool1] + [nn.AdaptiveMaxPool1d(1) \n",
    "                                              for out_channel, kernel in conv_layers])\n",
    "        \n",
    "        for layer in self.conv_list:\n",
    "            nn.init.kaiming_normal_(layer.weight.data)\n",
    "        \n",
    "        conv_out_num = (50 + sum([out_channels for out_channels, _ in conv_layers])) * 2\n",
    "        \n",
    "        # FC\n",
    "        fc1 = nn.Linear(conv_out_num, lin_layers[0])\n",
    "        self.fc_list = nn.ModuleList([fc1] + [nn.Linear(lin_layers[i], lin_layers[i+1]) \n",
    "                                              for i in range(len(lin_layers) - 1)])\n",
    "        \n",
    "        for layer in self.fc_list:\n",
    "            nn.init.kaiming_normal_(layer.weight.data)\n",
    "            \n",
    "        self.fc_out = nn.Linear(lin_layers[-1], num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc_out.weight.data)\n",
    "        \n",
    "        # BN\n",
    "        self.conv_bn_layers = nn.ModuleList([nn.BatchNorm1d(50)] + [nn.BatchNorm1d(out_channel)\n",
    "                                        for out_channel, _ in conv_layers])\n",
    "        self.lin_bn_layers = nn.ModuleList([nn.BatchNorm1d(layer)\n",
    "                                        for layer in lin_layers])\n",
    "\n",
    "        # Dropout\n",
    "        self.embed_dropout = nn.Dropout(dropout)\n",
    "        self.droput_layers = nn.ModuleList([nn.Dropout(dropout) for layer in lin_layers])\n",
    "        \n",
    "    def forward(self, input):\n",
    "        conv_out = torch.Tensor()\n",
    "        for conv, avg_pool, max_pool, bn in zip(self.conv_list, self.avg_pool_list, \n",
    "                                                self.max_pool_list, self.conv_bn_layers):\n",
    "            o = conv(input)\n",
    "            o = bn(o)\n",
    "            avg_o = avg_pool(o)\n",
    "            max_o = max_pool(o)\n",
    "            conv_out = torch.cat([conv_out.cpu(), avg_o.cpu(), max_o.cpu()], 1).to(device)\n",
    "        \n",
    "        x = F.relu(conv_out).flatten(1)\n",
    "        for fc, bn, dropout in zip(self.fc_list, self.lin_bn_layers, self.droput_layers):\n",
    "            x = F.relu(fc(x))\n",
    "            x = bn(x)\n",
    "            x = dropout(x)\n",
    "            \n",
    "        return F.softmax(self.fc_out(x), dim=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, loader, net, optimizer):\n",
    "    net.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = net(x)\n",
    "#         print(y.shape)\n",
    "#         print(pred.shape)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss/float(len(loader))\n",
    "\n",
    "def predict(dataset, loader, net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        corrects = eval_loss = 0\n",
    "        result = []\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.float().to(device)\n",
    "            pred = net(x)\n",
    "\n",
    "            result.append(torch.max(pred, 1)[1].view(y.size()).data)\n",
    "        return result\n",
    "\n",
    "def evaluate(dataset, loader, net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        corrects = eval_loss = 0\n",
    "\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            pred = net(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            corrects += (torch.max(pred, 1)[1].view(y.size()).data == y.data).sum()\n",
    "        #loss, correct count, accuracy\n",
    "        return eval_loss/float(len(loader)), corrects, corrects*100/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "lr = 0.01\n",
    "epoch = 1\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# splits = 3\n",
    "# kfold = sklearn.model_selection.StratifiedKFold(splits, shuffle=True)\n",
    "# for train_index, test_index in kfold.split(train_tfidf, train_y):\n",
    "#     net = ConvNN(train_tfidf.shape[1], len(train_y['age_group'].unique()), \n",
    "#                  [(128, 1), (64, 3), (32, 5), (20, 1000)], [900, 300], 0.5)\n",
    "#     net = net.to(device)\n",
    "#     train_dataset = TfidfDataset(train_tfidf[train_index], train_y.iloc[train_index])\n",
    "#     train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "#     validation_dataset = TfidfDataset(train_tfidf[test_index], train_y.iloc[test_index])\n",
    "#     validation_loader = DataLoader(validation_dataset, batch_size, shuffle=False)\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#     # learning rate decay\n",
    "#     for i in tqdm(range(epoch)):\n",
    "#         print(train(train_dataset, train_loader, net, optimizer))\n",
    "#         print(evaluate(validation_dataset, validation_loader, net))\n",
    "#     print(\"train acc:\", evaluate(train_dataset, train_loader, net))\n",
    "#     print(\"validation acc:\", evaluate(validation_dataset, validation_loader, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epoch = 1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "splits = 20\n",
    "kfold = sklearn.model_selection.StratifiedKFold(splits, shuffle=True)\n",
    "train_index, valid_index = next(iter(kfold.split(train_tfidf, train_y)))\n",
    "\n",
    "train_dataset = TfidfDataset(train_tfidf[train_index], train_y.iloc[train_index])\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "validation_dataset = TfidfDataset(train_tfidf[valid_index], train_y.iloc[valid_index])\n",
    "validation_loader = DataLoader(validation_dataset, batch_size, shuffle=False)\n",
    "test_dataset = TfidfDataset(test_tfidf)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNN(train_tfidf.shape[1], len(train_y['age_group'].unique()), \n",
    "                 [(128, 1), (64, 2), (48, 3), (32, 5), (20, 1000)], [800, 360], 0.3)\n",
    "# net.load_state_dict(torch.load('./nn-model.pkl')['state_dict'])\n",
    "net = net.to(device)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.005\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(epoch)):\n",
    "#     print(train(train_dataset, train_loader, net, optimizer))\n",
    "# #     print(\"train acc:\", evaluate(train_dataset, train_loader, net))\n",
    "#     print(\"validation acc:\", evaluate(validation_dataset, validation_loader, net))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch to fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.basic_train import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.train import *\n",
    "import fastai.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_loader, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, net, loss_func=criterion, metrics=[metrics.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.403561</td>\n",
       "      <td>1.432169</td>\n",
       "      <td>0.605652</td>\n",
       "      <td>42:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0438f057824e0a9988e4c0d2537cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=503), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation acc: (1.4321704553088421, tensor(60868, device='cuda:0'), tensor(60, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(\"validation acc:\", evaluate(validation_dataset, validation_loader, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': net.state_dict()}, './model/nn-model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be18bb42ed1c487bb8d41c8735967769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = predict(test_dataset, test_loader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for res in results:\n",
    "    for item in res:\n",
    "        results_list.append(item.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502500"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(test_uid)\n",
    "result.columns = ['id']\n",
    "result['label'] = results_list\n",
    "result['label'] = result['label'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 21 16:05:12 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 415.27       Driver Version: 415.27       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:81:00.0 Off |                  N/A |\r\n",
      "|  0%   52C    P2    63W / 270W |   9190MiB / 10989MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
