{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings('ignore')\n",
    "feature_path ='./feature/'\n",
    "res_path = './res/'\n",
    "data_path = './data/'\n",
    "second_round_path = './second round/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.read_csv(data_path+'transaction_train_new.csv')\n",
    "operation_df =  pd.read_csv(data_path+'operation_train_new.csv')\n",
    "label= pd.read_csv(data_path+'tag_train_new.csv')\n",
    "\n",
    "# transaction_test = pd.read_csv(data_path+'transaction_round1_new.csv')\n",
    "# operation_test = pd.read_csv(data_path+'operation_round1_new.csv')\n",
    "transaction_test = pd.read_csv(second_round_path+'test_transaction_round2.csv')\n",
    "operation_test = pd.read_csv(second_round_path+'test_operation_round2.csv')\n",
    "sample = pd.read_csv(data_path+'sample.csv')\n",
    "# operation_df = pd.merge(operation_df,label,on = 'UID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_count(df1,df2,columns,value,cname):\n",
    "    add = df1.groupby(columns)[value].count().reset_index().rename(columns = {value:cname})\n",
    "    df2=df2.merge(add,on=columns,how=\"left\")\n",
    "    del add\n",
    "    gc.collect()\n",
    "    return df2\n",
    "\n",
    "def merge_nunique(df1,df2,columns,value,cname):\n",
    "    add = df1.groupby(columns)[value].nunique().reset_index().rename(columns = {value:cname})\n",
    "    df2=df2.merge(add,on=columns,how=\"left\")\n",
    "    del add\n",
    "    gc.collect()\n",
    "    return df2\n",
    "\n",
    "def merge_value_count(df1,df2,col,value):\n",
    "    tmp = df1.groupby(col)[value].count().reset_index().rename(columns = {value:'cnt'})\n",
    "    df = tmp.pivot(index=col[0],columns=col[1],values='cnt').reset_index()\n",
    "    cname = [col[0]]\n",
    "    for index in range(1,len(df.columns)):\n",
    "        cname.append(str(col[1])+'_'+str(df.columns[index]))\n",
    "    df.columns=cname\n",
    "    df = df.fillna(0)\n",
    "    df2 = df2.merge(df,on=str(col[0]),how='left')\n",
    "    del df,df1\n",
    "    gc.collect()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_rate(df,columns,cname):\n",
    "    op_train = pd.merge(df, label, on = 'UID', how = 'left')\n",
    "    t_op_data = op_train[op_train['Tag'] == 0]\n",
    "    f_op_data = op_train[op_train['Tag'] == 1]\n",
    "    t_op_sample = t_op_data.sample(frac = 0.2, random_state = 88)\n",
    "    f_op_sample = f_op_data.sample(frac = 0.2, random_state = 88)\n",
    "    sample_data = pd.concat([t_op_sample,f_op_sample])\n",
    "    t_rate_op = sample_data.groupby(columns)['Tag'].mean().reset_index().rename(columns = {'Tag': cname})\n",
    "    t_rate_op[cname] = (t_rate_op[cname]*100).astype(int)\n",
    "    \n",
    "#     t_rate_op[cname] = pd.cut(t_rate_op[cname],bins = [-1,0,1,2,9,14,20,35,50,100],labels = False)\n",
    "    gc.collect()\n",
    "    return t_rate_op\n",
    "\n",
    "mode_tag_rate = get_tag_rate(operation_df,'mode','mode_Tag_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add = operation_df.groupby('mode')['Tag'].mean().reset_index().rename(columns = {'Tag':'mode_Tag_rate'})\n",
    "# add.mode_Tag_rate = (add.mode_Tag_rate*100).astype(int)\n",
    "# add.mode_Tag_rate = pd.cut(add.mode_Tag_rate,bins = [-1,0,1,2,9,14,20,35,50,100],labels = False)\n",
    "op_df = operation_df.merge(mode_tag_rate,on='mode',how=\"left\")\n",
    "op_test = operation_test.merge(mode_tag_rate,on='mode',how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_train = pd.merge(operation_df, label, on = 'UID', how = 'left')\n",
    "add = op_train.groupby('day')['Tag'].mean().reset_index().rename(columns = {'Tag':'day_Tag_rate'})\n",
    "add.day_Tag_rate = (add.day_Tag_rate*100).astype(int)\n",
    "#add.day_Tag_rate = pd.cut(add.day_Tag_rate,bins = [-1,6,11,13,100],labels = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_df = operation_df.merge(add,on='day',how=\"left\")\n",
    "operation_test = operation_test.merge(add,on='day',how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([469869., 157750.,  19769., 635007.,  39241.,  23851.,  34534.,\n",
       "         36195.,      0.,  44627.]),\n",
       " array([ 4. ,  6.3,  8.6, 10.9, 13.2, 15.5, 17.8, 20.1, 22.4, 24.7, 27. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(operation_df.day_Tag_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29728, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_df.groupby('UID')['day'].value_counts().unstack().reset_index().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate(df,columns,cname,bins=[-1,0,8,20,30,40,50,60,70,80,90,99,100]):\n",
    "    tt_train = pd.merge(df, label, on = 'UID', how = 'left')\n",
    "    rate = tt_train.groupby(columns)['Tag'].mean().reset_index().rename(columns = {'Tag':cname})\n",
    "    rate[cname] = pd.cut((rate[cname]*100).astype(int),bins,labels=False)\n",
    "    gc.collect()\n",
    "    return rate\n",
    "merchant_tag_rate = get_rate(transaction_df,'merchant','merchant_Tag_rate',bins=[-1,0,8,20,30,40,50,60,70,80,90,99,100])\n",
    "transaction_df = transaction_df.merge(merchant_tag_rate,on='merchant',how=\"left\")\n",
    "transaction_test = transaction_test.merge(merchant_tag_rate,on='merchant',how=\"left\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_day2week(df,cname,bins = [0,7,14,21,28,31]):\n",
    "    df[cname] = pd.cut(df['day'],bins,labels=False)\n",
    "    return df\n",
    "tr_df = cut_day2week(transaction_df,'week',bins = [0,7,14,21,28,31])\n",
    "tr_test = cut_day2week(transaction_test,'week',bins = [0,5,12,19,26,31])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op_fea(operation_df):\n",
    "    #op_day\n",
    "    op_fea = operation_df[['UID']].drop_duplicates()\n",
    "    tmp = operation_df.groupby('UID')['day'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','op_day_max','op_day_min','op_day_mean']\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    op_fea = merge_count(operation_df,op_fea,'UID','day','op_cnt')\n",
    "    \n",
    "# #     #1104,1\n",
    "#     tmp1 = operation_df.groupby('UID')['day'].value_counts().rename('day_counts').reset_index()\n",
    "#     tmp = tmp1.groupby('UID').day_counts.agg([max,min,np.mean,np.std]).reset_index()\n",
    "#     tmp.columns=['UID','op_day_counts_max','op_day_counts_min','op_day_counts_mean','op_day_counts_std']\n",
    "#     op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "#     del tmp1\n",
    "    \n",
    "#     1104,1 \n",
    "#     tmp1 = tmp['UID']\n",
    "#     tmp = (tmp[['op_day_counts_max','op_day_counts_min']]*100).\\\n",
    "#             apply(lambda x: x/operation_df.groupby('UID').day.count().values,axis=0)\n",
    "#     tmp['UID'] = tmp1\n",
    "#     tmp.columns=['UID','op_day_counts_max_r','op_day_counts_min_r']\n",
    "#     op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "#     op_fea = merge_nunique(operation_df,op_fea,'UID','day','op_day_nunique')\n",
    "#     op_fea['day_variety/sum'] = op_fea.op_day_nunique*100/op_fea.op_cnt\n",
    "#     #1205，1\n",
    "#     op_fea['op_day_counts_max-min'] = op_fea.op_day_counts_max-op_fea.op_day_counts_min\n",
    "    \n",
    "    #op_mode count\n",
    "    #op_fea = merge_count(operation_df,op_fea,'UID','mode','op_cnt')\n",
    "    op_fea = merge_nunique(operation_df,op_fea,'UID','mode','op_mode_nunique')\n",
    "    #1104，1\n",
    "    op_fea['mode_variety/sum'] = op_fea.op_mode_nunique*100/op_fea.op_cnt\n",
    "    \n",
    "    #success count\n",
    "    op_fea = merge_count(operation_df[operation_df.success==0],op_fea,'UID','mode','op_fail_cnt')\n",
    "    op_fea = merge_count(operation_df[operation_df.success==1],op_fea,'UID','mode','op_success_cnt')\n",
    "    op_fea['op_fail_cnt'] = op_fea['op_fail_cnt'].fillna(0)\n",
    "    op_fea['op_success_cnt'] = op_fea['op_success_cnt'].fillna(0)\n",
    "    1104,1\n",
    "    op_fea['op_success_rate'] = op_fea.op_success_cnt*100/op_fea.op_cnt\n",
    "    \n",
    "    #op_time\n",
    "    operation_df['op_hour'] = operation_df['time'].apply(lambda x:int(x.split(':')[0]))\n",
    "    tmp = operation_df.groupby('UID')['op_hour'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','op_hour_max','op_hour_min','op_hour_mean']\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "#     '''1104,2'''\n",
    "    tmp1 = operation_df.groupby('UID')['op_hour'].value_counts().rename('hour_counts').reset_index()\n",
    "    tmp = tmp1.groupby('UID').hour_counts.agg([max,min,np.mean,np.std]).reset_index()\n",
    "    tmp.columns=['UID','op_hour_counts_max','op_hour_counts_min','op_hour_counts_mean','op_hour_counts_std']\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #op_device1\n",
    "    for col in ['os','version','device1','device2','device_code1','device_code2','mac1','ip1','ip2',\\\n",
    "                'device_code3','mac2','wifi','geo_code','ip1_sub','ip2_sub']:\n",
    "        op_fea = merge_nunique(operation_df,op_fea,'UID',col,'op_'+col+'_nunique')\n",
    "\n",
    "    #op_os\n",
    "#     1104,2有效\n",
    "    op_fea['op_cnt/nunique'] = 1.0*op_fea.op_cnt/op_fea.op_os_nunique\n",
    "                \n",
    "    #1205，1\n",
    "    op_fea['op_ip1/device1'] = 100*op_fea.op_ip1_nunique/op_fea.op_device1_nunique\n",
    "    op_fea['op_device1/device_code1'] = 100*op_fea.op_device1_nunique/op_fea.op_device_code1_nunique\n",
    "    \n",
    "    '''1205,2'''\n",
    "    tmp = operation_df.groupby('UID')['mode_Tag_rate'].value_counts().unstack().reset_index()\n",
    "    tmp.fillna(0,inplace=True)\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "#     op_fea = pd.merge(op_fea,operation_df.groupby('UID')['os'].value_counts().\\\n",
    "#                       unstack().reset_index(),on='UID',how='left')\n",
    "# '''day_rate无效'''\n",
    "#     tmp = operation_df.groupby('UID')['day_Tag_rate'].value_counts().unstack().reset_index()\n",
    "#     tmp.fillna(0,inplace=True)\n",
    "#     op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "##     '''1106,1'''\n",
    "    \n",
    "#     tmp1 = operation_df.groupby('UID')['mode'].value_counts().rename('mode_counts').reset_index()\n",
    "#     tmp = tmp1.groupby('UID').mode_counts.agg([max,min,np.mean,np.std]).reset_index()\n",
    "#     tmp.columns=['UID','op_mode_counts_max','op_mode_counts_min','op_mode_counts_mean','op_mode_counts_std']\n",
    "#     op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    gc.collect()\n",
    "    return op_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_fea(transaction_df):\n",
    "    trans_fea = transaction_df[['UID']].drop_duplicates()\n",
    "    #trans_channel\n",
    "    trans_fea = merge_value_count(transaction_df,trans_fea,['UID','channel'],'day')\n",
    "    trans_fea = merge_count(transaction_df,trans_fea,'UID','channel','trans_cnt')\n",
    "    trans_fea = merge_nunique(transaction_df,trans_fea,'UID','channel','trans_channel_nunique')\n",
    "    \n",
    "    #day\n",
    "    tmp = transaction_df.groupby('UID')['day'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','transaction_day_max','transaction_day_min','transaction_day_mean']\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "#     #1105,2\n",
    "#     tmp1 = transaction_df.groupby('UID')['day'].value_counts().rename('day_counts').reset_index()\n",
    "#     tmp = tmp1.groupby('UID').day_counts.agg([max,min,np.mean,np.std]).reset_index()\n",
    "#     tmp.columns=['UID','trans_day_counts_max','trans_day_counts_min','trans_day_counts_mean','trans_day_counts_std']\n",
    "#     trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "#     del tmp1\n",
    "#     1105,2 \n",
    "#     tmp1 = tmp['UID']\n",
    "#     tmp = (tmp[['trans_day_counts_max','trans_day_counts_min']]*100).\\\n",
    "#             apply(lambda x: x/transaction_df.groupby('UID').day.count().values,axis=0)\n",
    "#     tmp['UID'] = tmp1\n",
    "#     tmp.columns=['UID','trans_day_counts_max_r','trans_day_counts_min_r']\n",
    "#     trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "\n",
    "#     trans_fea = merge_nunique(transaction_df,trans_fea,'UID','day','trans_day_nunique')\n",
    "#     trans_fea['day_variety/sum'] = trans_fea.trans_day_nunique*100/trans_fea.trans_cnt\n",
    "##    1205，1\n",
    "#     trans_fea['trans_day_counts_max-min'] = trans_fea.trans_day_counts_max-trans_fea.trans_day_counts_min\n",
    "\n",
    "    #time\n",
    "    transaction_df['trans_hour'] = transaction_df['time'].apply(lambda x:int(x.split(':')[0]))\n",
    "    tmp = transaction_df.groupby('UID')['trans_hour'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','trans_hour_max','trans_hour_min','trans_hour_mean']\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "# # 1105,2\n",
    "#     tmp1 = transaction_df.groupby('UID')['trans_hour'].value_counts().rename('hour_counts').reset_index()\n",
    "#     tmp = tmp1.groupby('UID').hour_counts.agg([max,min,np.mean,np.std]).reset_index()\n",
    "#     tmp.columns=['UID','trans_hour_counts_max','trans_hour_counts_min','trans_hour_counts_mean','trans_hour_counts_std']\n",
    "#     trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "    #trans_amt\n",
    "    tmp = transaction_df.groupby('UID')['trans_amt'].agg([max,min,np.mean,np.sum]).reset_index()\n",
    "    tmp.columns=['UID','transaction_amt_max','transaction_amt_min','transaction_amt_mean','transaction_amt_sum']\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "# #     #1105,2\n",
    "#     max_min = lambda x: abs(max(x)-min(x))\n",
    "#     tmp = transaction_df.groupby('UID')['trans_amt'].agg([np.std,max_min]).reset_index()\n",
    "#     tmp.columns=['UID','transaction_amt_std','transaction_amt_max-min']\n",
    "#     trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "    #amt_src1\n",
    "    trans_fea = merge_nunique(transaction_df,trans_fea,'UID','amt_src1','trans_amt_src1_nunique')\n",
    "    #bal\n",
    "    tmp = transaction_df.groupby('UID')['bal'].agg([max,min,np.mean,np.sum]).reset_index()\n",
    "    tmp.columns=['UID','transaction_bal_max','transaction_bal_min','transaction_bal_mean','transaction_bal_sum']\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "\n",
    "    #trans_type1 trans_type2\n",
    "    for col in ['trans_type2','market_type']:\n",
    "        trans_fea = merge_value_count(transaction_df,trans_fea,['UID',col],'day')\n",
    "        trans_fea = merge_nunique(transaction_df,trans_fea,'UID',col,'trans_'+col+'_nunique')\n",
    "    for col in ['trans_type1','merchant','code1','code2','acc_id1','device_code1','device_code2',\\\n",
    "                'device_code3','device1','device2','mac1','ip1','acc_id2','acc_id3','geo_code','market_code','ip1_sub']:\n",
    "        trans_fea = merge_nunique(transaction_df,trans_fea,'UID',col,'trans_'+col+'_nunique')\n",
    "        \n",
    "    '''1108,1,线下非常有效'''    \n",
    "#     trans_fea = merge_value_count(transaction_df,trans_fea,['UID','merchant_Tag_rate'],'day')#,线下非常有效,线上超级过拟合\n",
    "    tmp = transaction_df.groupby('UID')['merchant_Tag_rate'].value_counts().unstack().reset_index()\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "    '''1109,1'''\n",
    "#     tmp = transaction_df.groupby('UID').day.value_counts().unstack(fill_value=0).reset_index()\n",
    "#     trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "#     transaction_df['week'] = pd.cut(transaction_df.day,bins = [0,7,14,21,28,31],labels=False)\n",
    "    tmp = transaction_df.groupby('UID').week.value_counts().unstack(fill_value=0).reset_index()\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    tmp = transaction_df.groupby(['UID','week']).day.value_counts().rename('week_day_count').reset_index()\n",
    "    maxmin = lambda x: max(x)-min(x)\n",
    "    tmp = tmp.pivot_table(index = 'UID',columns = 'week',values = 'week_day_count',aggfunc= [max,min,np.std,maxmin]).reset_index()\n",
    "    tmp.fillna(-1,inplace=True)\n",
    "    trans_fea = pd.merge(trans_fea,tmp,on='UID',how='left')\n",
    "    \n",
    "    '''1112,01'''\n",
    "    \n",
    "    gc.collect()\n",
    "    return trans_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_fea = get_op_fea(op_df)\n",
    "trans_fea = get_trans_fea(transaction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_fea_test = get_op_fea(op_test)\n",
    "trans_fea_test = get_trans_fea(tr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30542, 85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_fea.to_csv(\"./data/feature/op_fea.csv\")\n",
    "trans_fea.to_csv(\"./data/feature/trans_fea.csv\")\n",
    "\n",
    "op_fea_test.to_csv(\"./data/feature/op_fea_test.csv\")\n",
    "trans_fea_test.to_csv(\"./data/feature/trans_fea_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = op_fea.merge(trans_fea, on='UID', how='outer')\n",
    "train_data = train_features.merge(label,on='UID',how='left')\n",
    "train_data = train_data.drop('UID', axis=1)\n",
    "test_features = op_fea_test.merge(trans_fea_test, on='UID', how='outer').sort_values(['UID'])\n",
    "\n",
    "\n",
    "UIDs = test_features['UID']\n",
    "test_features = test_features.drop('UID', axis=1)\n",
    "\n",
    "# columns_to_drop = [col for col in train_data.columns if col not in test_features.columns and col != 'Tag']\n",
    "# train_data = train_data.drop(columns_to_drop, axis=1)\n",
    "# columns_to_drop = [col for col in test_features.columns if col not in train_data.columns and col != 'Tag']\n",
    "# test_features = test_features.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#Fill nan with average\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "test_features = test_features.fillna(train_data.drop('Tag', axis=1).mean())\n",
    "\n",
    "\n",
    "columns_to_drop = [col for col in train_data.columns if col not in test_features.columns and col != 'Tag']\n",
    "train_data = train_data.drop(columns_to_drop, axis=1)\n",
    "columns_to_drop = [col for col in test_features.columns if col not in train_data.columns and col != 'Tag']\n",
    "test_features = test_features.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_scorer(estimator, x, y_true):\n",
    "    y_predict = estimator.predict_proba(x)[:, 1]\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    \n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import lightgbm as lgb\n",
    "import sklearn.ensemble\n",
    "import xgboost as xgb\n",
    "\n",
    "def cv(x, y, params={}, splits=5):\n",
    "    clf = lgb.LGBMClassifier(**params)\n",
    "#     clf = sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "#     clf = xgb.XGBClassifier(**params)\n",
    "    kfold = sklearn.model_selection.StratifiedKFold(splits, shuffle=True)\n",
    "    cv_score = sklearn.model_selection.cross_validate(clf, x, y, cv=kfold, scoring={\n",
    "        'tpr': tpr_scorer,\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1_micro',\n",
    "        'roc_auc': 'roc_auc'\n",
    "    }, return_train_score=True)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        \"num_leaves\": 200,\n",
    "        \"max_depth\": -1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        'min_child_samples': 100,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'scale_pos_weight': float(label[label.Tag==0].shape[0]) / label[label.Tag==1].shape[0],\n",
    "        'boost_from_average': True,\n",
    "        'min_child_weight': 1e-3,\n",
    "        \"subsample_for_bin\": 20000,\n",
    "        'max_bin': 512,\n",
    "        \"metric\": 'auc',\n",
    "        'reg_alpha': 3,\n",
    "        'reg_lambda': 5,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree':0.7, \n",
    "        'subsample_freq': 1,\n",
    "        'n_jobs': -1,\n",
    "}\n",
    "\n",
    "def run_cross_validation(x, y):\n",
    "    cv_result = cv(x, y, params=params, splits=5)\n",
    "    for scorer, score in cv_result.items():\n",
    "        print('%s: %s' % (scorer, score))\n",
    "        print('Average %s: %f' % (scorer, score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: [14.41619611 13.58223009 11.02795601 15.91861916 18.26247501]\n",
      "Average fit_time: 14.641495\n",
      "score_time: [0.85873365 0.90235806 0.69390106 1.03280997 0.86306977]\n",
      "Average score_time: 0.870175\n",
      "test_tpr: [0.7529755  0.77409568 0.76429405 0.76091015 0.75005834]\n",
      "Average test_tpr: 0.760467\n",
      "train_tpr: [1. 1. 1. 1. 1.]\n",
      "Average train_tpr: 1.000000\n",
      "test_accuracy: [0.96327774 0.9642399  0.96183451 0.96391918 0.961668  ]\n",
      "Average test_accuracy: 0.962988\n",
      "train_accuracy: [0.99983963 0.99991982 0.99967927 0.99987973 0.99963919]\n",
      "Average train_accuracy: 0.999792\n",
      "test_f1: [0.96327774 0.9642399  0.96183451 0.96391918 0.961668  ]\n",
      "Average test_f1: 0.962988\n",
      "train_f1: [0.99983963 0.99991982 0.99967927 0.99987973 0.99963919]\n",
      "Average train_f1: 0.999792\n",
      "test_roc_auc: [0.97075276 0.97386938 0.97153284 0.97100483 0.9687575 ]\n",
      "Average test_roc_auc: 0.971183\n",
      "train_roc_auc: [0.99999999 1.         0.99999997 0.99999997 0.99999995]\n",
      "Average train_roc_auc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "run_cross_validation(train_data.drop('Tag', axis=1).fillna(train_data.drop('Tag', axis=1).mean()).values, train_data.loc[:, 'Tag'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, params={}):\n",
    "    clf = lgb.LGBMClassifier(**params)\n",
    "#     clf = xgb.XGBClassifier(**params)\n",
    "    clf.fit(x, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(train_data.drop('Tag', axis=1).values, train_data.loc[:, 'Tag'].values, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_proba(test_features.values)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2747562365455236"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result > 0.5).sum() / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr_scorer(model, train_data.drop('Tag', axis=1).fillna(train_data.drop('Tag', axis=1).mean()).values, train_data.loc[:, 'Tag'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame()\n",
    "result_frame['UID'] = UIDs\n",
    "result_frame['Tag'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_frame.to_csv(res_path + 'fres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([             'UID',       'op_day_max',       'op_day_min',\n",
       "            'op_day_mean',           'op_cnt',  'op_mode_nunique',\n",
       "       'mode_variety/sum',      'op_fail_cnt',   'op_success_cnt',\n",
       "        'op_success_rate',\n",
       "       ...\n",
       "               ('std', 0),         ('std', 1),         ('std', 2),\n",
       "               ('std', 3),         ('std', 4),    ('<lambda>', 0),\n",
       "          ('<lambda>', 1),    ('<lambda>', 2),    ('<lambda>', 3),\n",
       "          ('<lambda>', 4)],\n",
       "      dtype='object', length=143)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
