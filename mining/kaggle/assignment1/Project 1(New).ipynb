{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocess\n",
    "import regression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/test set.csv')\n",
    "train_data = pd.read_csv('./data/trainSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(test_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_data), len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.values[:, :-1]\n",
    "train_target = train_data.values[:, -1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scale_processed_x, mean, std = preprocess.z_score_scaling(train_x)\n",
    "min_max_scaled_x = preprocess.min_max_scaling(train_x)\n",
    "processed_test, _, _ = preprocess.z_score_scaling(test_data.values, mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Discretization with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer is used for training and should return the trained parameters,\n",
    "# tester should receive x and the parameters and return the predicted item\n",
    "# args and kwargs are extra parameters to pass to the trainer.\n",
    "def k_fold(k, trainer, tester, x, target, *args, **kwargs):\n",
    "    samples, features = x.shape\n",
    "    fold_size = int(samples / k)\n",
    "    shuffled = np.hstack((x, target))\n",
    "    np.random.shuffle(shuffled)\n",
    "    shuffled_x = shuffled[:, :-1]\n",
    "    shuffled_target = shuffled[:, -1].reshape(-1, 1)\n",
    "    x_sets = np.array([shuffled_x[i * fold_size : (i+1) * fold_size] for i in range(k)])\n",
    "    target_sets = np.array([shuffled_target[i * fold_size: (i+1) * fold_size] for i in range(k)])\n",
    "    precisions_sum = 0\n",
    "    for i in range(k):\n",
    "        training_set = np.empty(shape=(0, features))\n",
    "        training_targets = np.empty(shape=(0, 1))\n",
    "        test_set = x_sets[i]\n",
    "        test_targets = target_sets[i]\n",
    "        for j in range(k):\n",
    "            if j != i:\n",
    "                training_set = np.concatenate((training_set, x_sets[j]))\n",
    "                training_targets = np.concatenate((training_targets, target_sets[j]))\n",
    "        the = trainer(training_set, training_targets, *args, **kwargs)\n",
    "        predicted = tester(test_set, the)\n",
    "        predicted = [1 if e > 0.5 else 0 for e in predicted]\n",
    "        corrects = 0\n",
    "        for j in range(fold_size):\n",
    "            if predicted[j] == test_targets[j]:\n",
    "                corrects += 1\n",
    "        print('%f at k=%d' % (corrects / fold_size, i))\n",
    "        precisions_sum += corrects / fold_size\n",
    "    result = precisions_sum / k\n",
    "    print('Average: %f' % result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5873417287275706\n",
      "0.6643015257513767\n",
      "0.6609301771769782\n",
      "0.6602388876789526\n",
      "0.605500 at k=0\n",
      "3.397101039052818\n",
      "0.6683400645042892\n",
      "0.6618265853731926\n",
      "0.6605565731127802\n",
      "0.609200 at k=1\n",
      "2.7235534411831623\n",
      "0.6645272647228058\n",
      "0.659916300554506\n",
      "0.6593062984421857\n",
      "0.603125 at k=2\n",
      "2.655693783682454\n",
      "0.6644451475640342\n",
      "0.6605751955084778\n",
      "0.6598511296136765\n",
      "0.606875 at k=3\n",
      "2.85293289488634\n",
      "0.6655182515166114\n",
      "0.6609652540625447\n",
      "0.6604146665523453\n",
      "0.610550 at k=4\n",
      "Average: 0.607050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60705"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 500\n",
    "lr = 0.2\n",
    "k_fold(5, regression.regression, regression.logistic_h, z_scale_processed_x, train_target, \n",
    "       regression.logistic_h, iters, lr, lbd=5.0, log=True, logInterval=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, label):\n",
    "    shuffled = np.hstack((x, label))\n",
    "    np.random.shuffle(shuffled)\n",
    "    shuffled_x = shuffled[:, :-1]\n",
    "    shuffled_target = shuffled[:, -1].reshape(-1, 1)\n",
    "    return shuffled_x, shuffled_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.479528125968463\n",
      "0.6677671836011526\n",
      "0.660634653431319\n",
      "0.6597069461473278\n",
      "0.6595142755955541\n"
     ]
    }
   ],
   "source": [
    "iters = 500\n",
    "lr = 0.2\n",
    "shuffled_x, shuffled_label = shuffle(z_scale_processed_x, train_target)\n",
    "the = regression.regression(z_scale_processed_x, train_target, regression.logistic_h, iters, lr, lbd=5.0, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regression.logistic_h(z_scale_processed_x, the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [1 if e > 0.5 else 0 for e in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121644"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurate = 0\n",
    "for i in range(len(result)):\n",
    "    if result[i] == train_target[i]:\n",
    "        accurate += 1\n",
    "accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139725\n"
     ]
    }
   ],
   "source": [
    "result = regression.logistic_h(processed_test, the)\n",
    "result = [1 if e > 0.5 else 0 for e in result]\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[i+1, 1 if result[i] > 0.5 else 0] for i in range(len(result))]).to_csv('result.csv', header=['Id', 'Predicted'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, features, hidden1, hidden2, out):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(features, hidden1)\n",
    "        self.layer2 = torch.nn.Linear(hidden1, hidden2)\n",
    "        self.layer3 = torch.nn.Linear(hidden2, out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o1 = self.layer1(x)\n",
    "        o2 = self.layer2(o1)\n",
    "        return self.layer3(o2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=32, out_features=260, bias=True)\n",
       "  (layer2): Linear(in_features=260, out_features=127, bias=True)\n",
       "  (layer3): Linear(in_features=127, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(z_scale_processed_x.shape[1], 260, 127, 2)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "def trainer(x, target):\n",
    "    for i in range(epoch):\n",
    "        o = net(torch.Tensor(x))\n",
    "        loss = loss_func(o, torch.Tensor(target).long().squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def tester(x, *args):\n",
    "    o = net(torch.Tensor(x))\n",
    "    return torch.max(o, 1)[1].numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607600 at k=0\n",
      "0.606700 at k=1\n",
      "0.606775 at k=2\n",
      "0.606200 at k=3\n",
      "0.607800 at k=4\n",
      "Average: 0.607015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.607015"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold(5, trainer, tester, z_scale_processed_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KBinsDiscretizer(encode='onehot-dense', n_bins=10, strategy='kmeans')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = train_x[:, 2]\n",
    "kb = KBinsDiscretizer(n_bins=10, encode='onehot-dense', strategy='kmeans')\n",
    "kb.fit(te.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "samples, features = train_x.shape\n",
    "discretized = np.empty(shape=(samples, 0))\n",
    "discretizer = []\n",
    "for i in range(features):\n",
    "    kb = KBinsDiscretizer(n_bins=20, encode='onehot-dense', strategy='uniform')\n",
    "    col = train_x[:, i].reshape(-1, 1)\n",
    "    kb.fit(col)\n",
    "    discretizer.append(kb)\n",
    "    print(i)\n",
    "    discretized = np.hstack((discretized, kb.transform(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 640)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.164201496857981\n",
      "0.8493710190342197\n",
      "0.750037518652131\n",
      "0.7174333294845987\n",
      "0.586625 at k=0\n",
      "7.036856801796076\n",
      "0.8543927005530155\n",
      "0.7598158076018899\n",
      "0.7249947703874418\n",
      "0.580575 at k=1\n",
      "6.7882568962446195\n",
      "0.8268020560109115\n",
      "0.7555480123263164\n",
      "0.7236738801810155\n",
      "0.586275 at k=2\n",
      "7.013016941453348\n",
      "0.8625226108011852\n",
      "0.7483188563307671\n",
      "0.7133159906789235\n",
      "0.592300 at k=3\n",
      "6.537905596745202\n",
      "0.8403178038529427\n",
      "0.7469365415608864\n",
      "0.7125058931226065\n",
      "0.582900 at k=4\n",
      "Average: 0.585735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5857349999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 200\n",
    "lr = 0.5\n",
    "k_fold(5, regression.regression, regression.logistic_h, discretized, train_target, \n",
    "       regression.logistic_h, iters, lr, lbd=5.0, log=True, logInterval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_train(x, y):\n",
    "    classifier = sklearn.ensemble.AdaBoostClassifier(base_estimator=sklearn.svm.SVC(probability=True,kernel='linear'))\n",
    "    classifier.fit(x, y.ravel())\n",
    "    return classifier\n",
    "\n",
    "def sk_test(x, classifier):\n",
    "    return classifier.predict(x).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold(5, sk_train, sk_test, z_scale_processed_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sk_train(z_scale_processed_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98812"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = classifier.predict(z_scale_processed_x)\n",
    "accurate = 0\n",
    "for i in range(len(res)):\n",
    "    if res[i] == train_target[i]:\n",
    "        accurate += 1\n",
    "accurate / len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111613.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = classifier.predict(processed_test)\n",
    "res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[i+1, int(res[i])] for i in range(len(res))]).to_csv('forest.csv', header=['Id', 'Predicted'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
